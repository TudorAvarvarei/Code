{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tavar\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python version: 3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]\n",
      "stable_baselines3 version: 2.1.0\n",
      "torch version: 2.1.0+cu121\n",
      "cuda available: True\n",
      "cuda version: 12.1\n",
      "cudnn version: 8801\n",
      "device: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import stable_baselines3\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "print(\"python version:\", sys.version)\n",
    "print(\"stable_baselines3 version:\", stable_baselines3.__version__)\n",
    "print(\"torch version:\", torch.__version__)\n",
    "print(\"cuda available:\", torch.cuda.is_available())\n",
    "print(\"cuda version:\", torch.version.cuda)\n",
    "print(\"cudnn version:\", torch.backends.cudnn.version())\n",
    "\n",
    "# set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n",
    "\n",
    "# set torch default device\n",
    "torch.device(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Equation of Motion 3D Quadcopter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload sympy\n",
    "from sympy import symbols, Matrix, lambdify, Array, sin, cos, tan\n",
    "\n",
    "# Equations of motion 3D quadcopter from https://arxiv.org/pdf/2304.13460.pdf\n",
    "\n",
    "# w1,w2,w3,w4 are the motor speeds normalized to [-1,1]\n",
    "# u1,u2,u3,u4 are the motor commands normalized to [-1,1]\n",
    "\n",
    "state = symbols('x y z v_x v_y v_z phi theta psi p q r w1 w2 w3 w4')\n",
    "x,y,z,vx,vy,vz,phi,theta,psi,p,q,r,w1,w2,w3,w4 = state\n",
    "control = symbols('u_1 u_2 u_3 u_4')\n",
    "u1,u2,u3,u4 = control\n",
    "disturbances = symbols('M_ext_x M_ext_y M_ext_z F_ext_x F_ext_y F_ext_z')\n",
    "M_ext_x, M_ext_y, M_ext_z, F_ext_x, F_ext_y, F_ext_z = disturbances\n",
    "\n",
    "# parameters from https://arxiv.org/pdf/2304.13460.pdf\n",
    "g = 9.81\n",
    "Ixx = 0.000906\n",
    "Iyy = 0.001242\n",
    "Izz = 0.002054\n",
    "\n",
    "k_x  = 1.07933887e-05\n",
    "k_y  = 9.65250793e-06\n",
    "k_z  = 2.7862899e-05\n",
    "k_w  = 4.36301076e-08\n",
    "k_h  = 0.0625501332\n",
    "k_p  = 1.4119331e-09\n",
    "k_pv = -0.00797101848\n",
    "k_q  = 1.21601884e-09\n",
    "k_qv = 0.0129263739\n",
    "k_r1 = 2.57035545e-06\n",
    "k_r2 = 4.10923364e-07\n",
    "k_rr = 0.000812932607\n",
    "\n",
    "tau = 0.06\n",
    "w_min = 3000\n",
    "w_max = 11000\n",
    "\n",
    "\n",
    "# Rotation matrix \n",
    "Rx = Matrix([[1, 0, 0], [0, cos(phi), -sin(phi)], [0, sin(phi), cos(phi)]])\n",
    "Ry = Matrix([[cos(theta), 0, sin(theta)], [0, 1, 0], [-sin(theta), 0, cos(theta)]])\n",
    "Rz = Matrix([[cos(psi), -sin(psi), 0], [sin(psi), cos(psi), 0], [0, 0, 1]])\n",
    "R = Rz*Ry*Rx\n",
    "\n",
    "# Body velocity\n",
    "vbx, vby, vbz = R.T@Matrix([vx,vy,vz])\n",
    "\n",
    "# normalized motor speeds to rpm\n",
    "W1 = (w1+1)/2*(w_max-w_min) + w_min\n",
    "W2 = (w2+1)/2*(w_max-w_min) + w_min\n",
    "W3 = (w3+1)/2*(w_max-w_min) + w_min\n",
    "W4 = (w4+1)/2*(w_max-w_min) + w_min\n",
    "\n",
    "# first order delay\n",
    "d_w1 = (u1 - w1)/tau\n",
    "d_w2 = (u2 - w2)/tau\n",
    "d_w3 = (u3 - w3)/tau\n",
    "\n",
    "d_w4 = (u4 - w4)/tau\n",
    "\n",
    "# derivative of rpm: d/dt[((w+1)/2*(w_max-w_min) + w_min)]\n",
    "d_W1 = d_w1/2*(w_max-w_min)\n",
    "d_W2 = d_w2/2*(w_max-w_min)\n",
    "d_W3 = d_w3/2*(w_max-w_min)\n",
    "d_W4 = d_w4/2*(w_max-w_min)\n",
    "\n",
    "# Thrust and Drag\n",
    "T = -k_w*(W1**2 + W2**2 + W3**2 + W4**2) - k_h*(vbx**2+vby**2) - k_z*vbz*(W1+W2+W3+W4) + F_ext_z\n",
    "Dx = -k_x*vbx*(W1+W2+W3+W4) + F_ext_x\n",
    "Dy = -k_y*vby*(W1+W2+W3+W4) + F_ext_y\n",
    "\n",
    "# Moments\n",
    "Mx = k_p*(W1**2-W2**2-W3**2+W4**2) + k_pv*vby + M_ext_x\n",
    "My = k_q*(W1**2+W2**2-W3**2-W4**2) + k_qv*vbx + M_ext_y\n",
    "Mz = k_r1*(-W1+W2-W3+W4) + k_r2*(-d_W1+d_W2-d_W3+d_W4) - k_rr*r + M_ext_z\n",
    "\n",
    "# Dynamics\n",
    "d_x = vx\n",
    "d_y = vy\n",
    "d_z = vz\n",
    "\n",
    "d_vx, d_vy, d_vz = Matrix([0,0,g]) + R@Matrix([Dx, Dy,T])\n",
    "\n",
    "d_phi   = p + q*sin(phi)*tan(theta) + r*cos(phi)*tan(theta)\n",
    "d_theta = q*cos(phi) - r*sin(phi)\n",
    "d_psi   = q*sin(phi)/cos(theta) + r*cos(phi)/cos(theta)\n",
    "\n",
    "d_p     = (q*r*(Iyy-Izz) + Mx)/Ixx\n",
    "d_q     = (p*r*(Izz-Ixx) + My)/Iyy\n",
    "d_r     = (p*q*(Ixx-Iyy) + Mz)/Izz\n",
    "\n",
    "# State space model\n",
    "f = [d_x, d_y, d_z, d_vx, d_vy, d_vz, d_phi, d_theta, d_psi, d_p, d_q, d_r, d_w1, d_w2, d_w3, d_w4]\n",
    "\n",
    "# lambdify\n",
    "f_func = lambdify((Array(state), Array(control), Array(disturbances)), Array(f), 'numpy')\n",
    "\n",
    "# extra functions\n",
    "get_body_velocity = lambdify((Array(state),), Array([vbx, vby, vbz]), 'numpy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228 µs ± 10.4 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# time f_func with random input\n",
    "import numpy as np\n",
    "state = np.random.rand(16)\n",
    "control = np.random.rand(4)\n",
    "disturbances = np.random.rand(6)\n",
    "%timeit f_func(state, control, disturbances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thrust_model:  Sequential(\n",
      "  (0): Linear(in_features=7, out_features=32, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n",
      "moment_model:  Sequential(\n",
      "  (0): Linear(in_features=10, out_features=32, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=32, out_features=3, bias=True)\n",
      ")\n",
      "states:  [[ 0.          1.          2.          3.          4.          5.\n",
      "   0.          0.          0.          9.         10.         11.\n",
      "  12.         13.         14.         15.        ]\n",
      " [-0.76010686  0.265381    0.4973284   1.2580922  -1.558399   -0.56207764\n",
      "  -0.35731894 -0.11949297  0.6055417  -0.22994469  1.6004206  -0.19230877\n",
      "   0.43437323 -0.6362362  -0.8493721  -0.9954662 ]\n",
      " [-1.0306864  -0.5253012  -0.03764461 -0.50420785 -0.761236    0.12607075\n",
      "   2.1254125  -0.06646167  1.1255801   1.9757395   2.3767068  -0.5364673\n",
      "  -1.6644132  -1.7169895  -1.5017667   0.9605665 ]\n",
      " [-0.29614344 -0.10947627  0.45777488  0.03482734 -1.5657341  -0.01588125\n",
      "  -0.25255352 -1.1540402  -0.11146359 -0.38635495 -0.47430232  0.22554229\n",
      "   1.1967582  -1.1507801   0.6878848   0.9102133 ]]\n",
      "vb:  [[ 3.          4.          5.        ]\n",
      " [ 0.07928796 -1.6699243  -1.2379017 ]\n",
      " [-0.89379865  0.09098332 -0.20602357]\n",
      " [ 0.06998839 -1.4535973  -0.57891726]]\n",
      "thrust:  [[36.098232 ]\n",
      " [ 1.1827052]\n",
      " [ 3.3525352]\n",
      " [ 1.5082624]] float32\n",
      "moment:  [[ 0.2847767  -0.22512697 -0.05896095]\n",
      " [ 0.04805128 -0.02874791 -0.02275201]\n",
      " [ 0.01328364  0.01935006 -0.03431566]\n",
      " [-0.01461925  0.00542307 -0.01270849]] float32\n"
     ]
    }
   ],
   "source": [
    "# load thrust and moment model from NNDroneModel\n",
    "thrust_model = torch.load('NNDroneModel/thrust_model.pt')\n",
    "moment_model = torch.load('NNDroneModel/moment_model.pt')\n",
    "print('thrust_model: ', thrust_model)\n",
    "print('moment_model: ', moment_model)\n",
    "\n",
    "# the models will be used for inference on the CPU\n",
    "thrust_model.eval()\n",
    "moment_model.eval()\n",
    "\n",
    "# turn of grad\n",
    "for p in thrust_model.parameters():\n",
    "    p.requires_grad = False\n",
    "for p in moment_model.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "# convert networks to numpy functions\n",
    "thrust_model_np = lambda x: thrust_model(torch.from_numpy(x.astype(np.float32))).numpy()\n",
    "moment_model_np = lambda x: moment_model(torch.from_numpy(x.astype(np.float32))).numpy()\n",
    "\n",
    "# create a function that computes the thrust and moment from the world states (batched)\n",
    "states = np.random.randn(4, 16).astype(np.float32)\n",
    "states[0] = [0,1,2,3,4,5,0,0,0,9,10,11,12,13,14,15]\n",
    "print('states: ', states)\n",
    "vb = get_body_velocity(states.T).T\n",
    "print('vb: ', vb)\n",
    "\n",
    "def thrust_moment_model_world_states(states):\n",
    "    w = states[:, 12:16]\n",
    "    omega = states[:, 9:12]\n",
    "    vb = get_body_velocity(states.T).T\n",
    "    x_in_thrust = np.concatenate((w, vb), axis=1)\n",
    "    # print('x_in_thrust: ', x_in_thrust)\n",
    "    x_in_moment = np.concatenate((x_in_thrust, omega), axis=1)\n",
    "    # print('x_in_moment: ', x_in_moment)\n",
    "    return thrust_model_np(x_in_thrust), moment_model_np(x_in_moment)\n",
    "\n",
    "# test the function\n",
    "thrust, moment = thrust_moment_model_world_states(states)\n",
    "print('thrust: ', thrust, thrust.dtype)\n",
    "print('moment: ', moment, moment.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the 3D Quad Gates Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Efficient vectorized version of the environment\n",
    "from gymnasium.spaces.box import Box\n",
    "from stable_baselines3.common.vec_env import VecEnv\n",
    "\n",
    "class Quadcopter3DGates(VecEnv):\n",
    "    def __init__(self,\n",
    "                 num_envs,\n",
    "                 gates_pos,\n",
    "                 gate_yaw,\n",
    "                 start_pos,\n",
    "                 gates_ahead=0,\n",
    "                 pause_if_collision=False,\n",
    "                 ):\n",
    "        \n",
    "        # Define the race track\n",
    "        self.start_pos = start_pos.astype(np.float32)\n",
    "        self.gate_pos = gates_pos.astype(np.float32)\n",
    "        self.gate_yaw = gate_yaw.astype(np.float32)\n",
    "        self.num_gates = gates_pos.shape[0]\n",
    "        self.gates_ahead = gates_ahead\n",
    "        \n",
    "        # Pause if collision\n",
    "        self.pause_if_collision = pause_if_collision\n",
    "\n",
    "        # Calculate relative gates\n",
    "        # pos,yaw of gate i in reference frame of gate i-1 (assumes a looped track)\n",
    "        self.gate_pos_rel = np.zeros((self.num_gates,3), dtype=np.float32)\n",
    "        self.gate_yaw_rel = np.zeros(self.num_gates, dtype=np.float32)\n",
    "        for i in range(0,self.num_gates):\n",
    "            self.gate_pos_rel[i] = self.gate_pos[i] - self.gate_pos[i-1]\n",
    "            # Rotation matrix\n",
    "            R = np.array([\n",
    "                [np.cos(self.gate_yaw[i-1]), np.sin(self.gate_yaw[i-1])],\n",
    "                [-np.sin(self.gate_yaw[i-1]), np.cos(self.gate_yaw[i-1])]\n",
    "            ])\n",
    "            self.gate_pos_rel[i,0:2] = R@self.gate_pos_rel[i,0:2]\n",
    "            self.gate_yaw_rel[i] = self.gate_yaw[i] - self.gate_yaw[i-1]\n",
    "\n",
    "        # Define the target gate for each environment\n",
    "        self.target_gates = np.zeros(num_envs, dtype=int)\n",
    "\n",
    "        # action space: [cmd1, cmd2, cmd3, cmd4]\n",
    "        action_space = Box(low=-1, high=1, shape=(4,))\n",
    "\n",
    "        # observation space: pos[G], vel[G], att[eulerB->G], rates[B], rpms, future_gates[G], future_gate_dirs[G]\n",
    "        # [G] = reference frame aligned with target gate\n",
    "        # [B] = body frame\n",
    "        self.state_len = 16+4*self.gates_ahead + 4\n",
    "        observation_space = Box(\n",
    "            low  = np.array([-np.inf]*self.state_len),\n",
    "            high = np.array([ np.inf]*self.state_len)\n",
    "        )\n",
    "\n",
    "        # Initialize the VecEnv\n",
    "        VecEnv.__init__(self,num_envs, observation_space, action_space)\n",
    "\n",
    "        # world state: pos[W], vel[W], att[eulerB->W], rates[B], rpms\n",
    "        self.world_states = np.zeros((num_envs,16), dtype=np.float32)\n",
    "        # observation state\n",
    "        self.states = np.zeros((num_envs,self.state_len), dtype=np.float32)\n",
    "\n",
    "        # Define any other environment-specific parameters\n",
    "        self.max_steps = 1200      # Maximum number of steps in an episode\n",
    "        self.dt = np.float32(0.01) # Time step duration\n",
    "\n",
    "        self.step_counts = np.zeros(num_envs, dtype=int)\n",
    "        self.actions = np.zeros((num_envs,4), dtype=np.float32)\n",
    "        self.dones = np.zeros(num_envs, dtype=bool)\n",
    "        self.final_gate_passed = np.zeros(num_envs, dtype=bool)\n",
    "\n",
    "        self.update_states = self.update_states_gate\n",
    "        \n",
    "        self.disturbance_ranges = np.zeros((6,2), dtype=np.float32)\n",
    "        self.disturbances = np.zeros((num_envs,6), dtype=np.float32)\n",
    "\n",
    "        self.disturbance_scale = 1\n",
    "\n",
    "        self.pause = False\n",
    "\n",
    "    def update_states_world(self):\n",
    "        self.states = self.world_states\n",
    "\n",
    "    def update_states_gate(self):\n",
    "        # Transform pos and vel in gate frame\n",
    "        gate_pos = self.gate_pos[self.target_gates%self.num_gates]\n",
    "        gate_yaw = self.gate_yaw[self.target_gates%self.num_gates]\n",
    "\n",
    "        # Rotation matrix from world frame to gate frame\n",
    "        R = np.array([\n",
    "            [np.cos(gate_yaw), np.sin(gate_yaw)],\n",
    "            [-np.sin(gate_yaw), np.cos(gate_yaw)]\n",
    "        ]).transpose((2,1,0))\n",
    "\n",
    "        # new state array to prevent the weird bug related to indexing ([:] syntax)\n",
    "        new_states = np.zeros_like(self.states)\n",
    "\n",
    "        # Update positions\n",
    "        pos_W = self.world_states[:,0:3]\n",
    "        pos_G = (pos_W[:,np.newaxis,0:2] - gate_pos[:,np.newaxis,0:2]) @ R\n",
    "        new_states[:,0:2] = pos_G[:,0,:]\n",
    "        new_states[:,2] = pos_W[:,2] - gate_pos[:,2]\n",
    "\n",
    "        # Update velocities\n",
    "        vel_W = self.world_states[:,3:6]\n",
    "        vel_G = (vel_W[:,np.newaxis,0:2]) @ R\n",
    "        new_states[:,3:5] = vel_G[:,0,:]\n",
    "        new_states[:,5] = vel_W[:,2]\n",
    "\n",
    "        # Update attitude\n",
    "        new_states[:,6:8] = self.world_states[:,6:8]\n",
    "        yaw = self.world_states[:,8] - gate_yaw\n",
    "        yaw %= 2*np.pi\n",
    "        yaw[yaw > np.pi] -= 2*np.pi\n",
    "        yaw[yaw < -np.pi] += 2*np.pi\n",
    "        new_states[:,8] = yaw\n",
    "\n",
    "        # Update rates\n",
    "        new_states[:,9:12] = self.world_states[:,9:12]\n",
    "\n",
    "        # Update rpms\n",
    "        new_states[:,12:16] = self.world_states[:,12:16]\n",
    "\n",
    "        # Update future gates relative to current gate ([0,0,0,0] for out of bounds)\n",
    "        for i in range(self.gates_ahead):\n",
    "            indices = (self.target_gates+i+1)\n",
    "            # loop when out of bounds\n",
    "            indices = indices % self.num_gates\n",
    "            valid = indices < self.num_gates\n",
    "            new_states[valid,16+4*i:16+4*i+3] = self.gate_pos_rel[indices[valid]]\n",
    "            new_states[valid,16+4*i+3] = self.gate_yaw_rel[indices[valid]]\n",
    "        \n",
    "        Mx = self.disturbances[:,0]\n",
    "        My = self.disturbances[:,1]\n",
    "        Mz = self.disturbances[:,2]\n",
    "        Fz = self.disturbances[:,5]\n",
    "\n",
    "        Mx_min = self.disturbance_ranges[0,0]\n",
    "        Mx_max = self.disturbance_ranges[0,1]\n",
    "        if Mx_min == Mx_max:\n",
    "            Mx_min -= 1\n",
    "            Mx_max += 1\n",
    "\n",
    "        My_min = self.disturbance_ranges[1,0]\n",
    "        My_max = self.disturbance_ranges[1,1]\n",
    "        if My_min == My_max:\n",
    "            My_min -= 1\n",
    "            My_max += 1\n",
    "        \n",
    "        Mz_min = self.disturbance_ranges[2,0]\n",
    "        Mz_max = self.disturbance_ranges[2,1]\n",
    "        if Mz_min == Mz_max:\n",
    "            Mz_min -= 1\n",
    "            Mz_max += 1\n",
    "\n",
    "        Fz_min = self.disturbance_ranges[5,0]\n",
    "        Fz_max = self.disturbance_ranges[5,1]\n",
    "        if Fz_min == Fz_max:\n",
    "            Fz_min -= 1\n",
    "            Fz_max += 1\n",
    "\n",
    "        new_states[:,16+4*self.gates_ahead:] = np.array([\n",
    "            2*(Mx-Mx_min)/(Mx_max-Mx_min)-1, # Mx\n",
    "            2*(My-My_min)/(My_max-My_min)-1, # My\n",
    "            2*(Mz-Mz_min)/(Mz_max-Mz_min)-1, # Mz\n",
    "            2*(Fz-Fz_min)/(Fz_max-Fz_min)-1, # Fz\n",
    "        ]).T\n",
    "\n",
    "        self.states = new_states\n",
    "\n",
    "    def reset_(self, dones):\n",
    "        num_reset = dones.sum()\n",
    "\n",
    "        x0 = np.random.uniform(-0.5,0.5, size=(num_reset,)) + self.start_pos[0]\n",
    "        y0 = np.random.uniform(-0.5,0.5, size=(num_reset,)) + self.start_pos[1]\n",
    "        z0 = np.random.uniform(-0.5,0.5, size=(num_reset,)) + self.start_pos[2]\n",
    "        \n",
    "        vx0 = np.random.uniform(-0.5,0.5, size=(num_reset,))\n",
    "        vy0 = np.random.uniform(-0.5,0.5, size=(num_reset,))\n",
    "        vz0 = np.random.uniform(-0.5,0.5, size=(num_reset,))\n",
    "        \n",
    "        phi0   = np.random.uniform(-np.pi/9,np.pi/9, size=(num_reset,))\n",
    "        theta0 = np.random.uniform(-np.pi/9,np.pi/9, size=(num_reset,))\n",
    "        psi0   = np.random.uniform(-np.pi,np.pi, size=(num_reset,))\n",
    "        \n",
    "        p0 = np.random.uniform(-0.1,0.1, size=(num_reset,))\n",
    "        q0 = np.random.uniform(-0.1,0.1, size=(num_reset,))\n",
    "        r0 = np.random.uniform(-0.1,0.1, size=(num_reset,))\n",
    "        \n",
    "        w10 = np.random.uniform(-1,1, size=(num_reset,))\n",
    "        w20 = np.random.uniform(-1,1, size=(num_reset,))\n",
    "        w30 = np.random.uniform(-1,1, size=(num_reset,))\n",
    "        w40 = np.random.uniform(-1,1, size=(num_reset,))\n",
    "\n",
    "        self.world_states[dones] = np.stack([x0, y0, z0, vx0, vy0, vz0, phi0, theta0, psi0, p0, q0, r0, w10, w20, w30, w40], axis=1)\n",
    "\n",
    "        self.step_counts[dones] = np.zeros(num_reset)\n",
    "        \n",
    "        self.target_gates[dones] = np.zeros(num_reset, dtype=int)\n",
    "\n",
    "        M_ext_x = np.random.uniform(self.disturbance_ranges[0,0], self.disturbance_ranges[0,1], size=(num_reset,))\n",
    "        M_ext_y = np.random.uniform(self.disturbance_ranges[1,0], self.disturbance_ranges[1,1], size=(num_reset,))\n",
    "        M_ext_z = np.random.uniform(self.disturbance_ranges[2,0], self.disturbance_ranges[2,1], size=(num_reset,))\n",
    "        F_ext_x = np.random.uniform(self.disturbance_ranges[3,0], self.disturbance_ranges[3,1], size=(num_reset,))\n",
    "        F_ext_y = np.random.uniform(self.disturbance_ranges[4,0], self.disturbance_ranges[4,1], size=(num_reset,))\n",
    "        F_ext_z = np.random.uniform(self.disturbance_ranges[5,0], self.disturbance_ranges[5,1], size=(num_reset,))\n",
    "        \n",
    "        self.disturbances[dones] = self.disturbance_scale*np.stack([M_ext_x, M_ext_y, M_ext_z, F_ext_x, F_ext_y, F_ext_z], axis=1)\n",
    "\n",
    "        # update states\n",
    "        self.update_states()\n",
    "        return self.states\n",
    "    \n",
    "    def reset(self):\n",
    "        return self.reset_(np.ones(self.num_envs, dtype=bool))\n",
    "\n",
    "    def step_async(self, actions):\n",
    "        self.actions = actions\n",
    "    \n",
    "    def step_wait(self):\n",
    "        # Residual nn model\n",
    "        d = np.zeros((self.num_envs,6), dtype=np.float32)\n",
    "        thurst, moment = thrust_moment_model_world_states(self.world_states)\n",
    "        d[:,0:3] = moment\n",
    "        d[:,5:6] = thurst\n",
    "\n",
    "        # Add disturbances\n",
    "        d += self.disturbances\n",
    "        \n",
    "\n",
    "        new_states = self.world_states + self.dt*f_func(self.world_states.T, self.actions.T, d.T).T\n",
    "        # new_states = self.world_states + self.dt*f_func(self.world_states.T, self.actions.T, self.disturbances[self.step_counts].T).T\n",
    "        self.step_counts += 1\n",
    "\n",
    "        pos_old = self.world_states[:,0:3]\n",
    "        pos_new = new_states[:,0:3]\n",
    "        pos_gate = self.gate_pos[self.target_gates%self.num_gates]\n",
    "        yaw_gate = self.gate_yaw[self.target_gates%self.num_gates]\n",
    "\n",
    "        # Rewards\n",
    "        d2g_old = np.linalg.norm(pos_old - pos_gate, axis=1)\n",
    "        d2g_new = np.linalg.norm(pos_new - pos_gate, axis=1)\n",
    "        rat_penalty = 0*0.01*np.linalg.norm(new_states[:,9:12], axis=1)\n",
    "        rewards = d2g_old - d2g_new - rat_penalty\n",
    "        \n",
    "        # Gate passing/collision\n",
    "        normal = np.array([np.cos(yaw_gate), np.sin(yaw_gate)]).T\n",
    "        # dot product of normal and position vector over axis 1\n",
    "        pos_old_projected = (pos_old[:,0]-pos_gate[:,0])*normal[:,0] + (pos_old[:,1]-pos_gate[:,1])*normal[:,1]\n",
    "        pos_new_projected = (pos_new[:,0]-pos_gate[:,0])*normal[:,0] + (pos_new[:,1]-pos_gate[:,1])*normal[:,1]\n",
    "        passed_gate_plane = (pos_old_projected < 0) & (pos_new_projected > 0)\n",
    "        gate_passed = passed_gate_plane & np.all(np.abs(pos_new - pos_gate)<0.5, axis=1)\n",
    "        gate_collision = passed_gate_plane & np.any(np.abs(pos_new - pos_gate)>0.5, axis=1)\n",
    "\n",
    "        # Gate reward + dist penalty\n",
    "        rewards[gate_passed] = 10 - 10*d2g_new[gate_passed]\n",
    "        \n",
    "        # Gate collision penalty\n",
    "        rewards[gate_collision] = -10\n",
    "\n",
    "        # Ground collision penalty (z > 0)\n",
    "        ground_collision = new_states[:,2] > 0\n",
    "        rewards[ground_collision] = -10\n",
    "        \n",
    "        # Check out of bounds\n",
    "        # outside grid abs(x,y)>10\n",
    "        # prevent numerical issues: abs(p,q,r) < 1000\n",
    "        out_of_bounds = np.any(np.abs(new_states[:,0:2]) > 10, axis=1) | np.any(np.abs(new_states[:,9:12]) > 1000, axis=1)\n",
    "        rewards[out_of_bounds] = -10\n",
    "        \n",
    "        # Check number of steps\n",
    "        max_steps_reached = self.step_counts >= self.max_steps\n",
    "\n",
    "        # Update target gate\n",
    "        self.target_gates[gate_passed] += 1\n",
    "        self.target_gates[gate_passed] %= self.num_gates\n",
    "        \n",
    "        # Check if final gate has been passed\n",
    "        # self.final_gate_passed = self.target_gates >= self.num_gates\n",
    "\n",
    "        # give reward for passing final gate\n",
    "        rewards[self.final_gate_passed] = 10\n",
    "        \n",
    "        # Check if the episode is done\n",
    "        dones = max_steps_reached | ground_collision | gate_collision | out_of_bounds #| self.final_gate_passed\n",
    "        self.dones = dones\n",
    "        \n",
    "        # Pause if collision\n",
    "        if self.pause:\n",
    "            dones = dones & ~dones\n",
    "            self.dones = dones\n",
    "        elif self.pause_if_collision:\n",
    "            # dones = max_steps_reached | final_gate_passed | out_of_bounds\n",
    "            update = ~dones #~(gate_collision | ground_collision)\n",
    "            # Update world states\n",
    "            self.world_states[update] = new_states[update]\n",
    "            self.update_states()\n",
    "            # Reset env if done (and update states)\n",
    "            # self.reset_(dones)\n",
    "        else:\n",
    "            # Update world states\n",
    "            self.world_states = new_states\n",
    "            # reset env if done (and update states)\n",
    "            self.reset_(dones)\n",
    "\n",
    "\n",
    "        # Write info dicts\n",
    "        infos = [{}] * self.num_envs\n",
    "        for i in range(self.num_envs):\n",
    "            if dones[i]:\n",
    "                infos[i][\"terminal_observation\"] = self.states[i]\n",
    "            if max_steps_reached[i]:\n",
    "                infos[i][\"TimeLimit.truncated\"] = True\n",
    "        return self.states, rewards, dones, infos\n",
    "    \n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "    def seed(self, seed=None):\n",
    "        pass\n",
    "\n",
    "    def get_attr(self, attr_name, indices=None):\n",
    "        pass\n",
    "\n",
    "    def set_attr(self, attr_name, value, indices=None):\n",
    "        pass\n",
    "\n",
    "    def env_method(self, method_name, *method_args, indices=None, **method_kwargs):\n",
    "        pass\n",
    "\n",
    "    def env_is_wrapped(self, wrapper_class, indices=None):\n",
    "        return [False]*self.num_envs\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        # Outputs a dict containing all information for rendering\n",
    "        state_dict = dict(zip(['x','y','z','vx','vy','vz','phi','theta','psi','p','q','r','w1','w2','w3','w4'], self.world_states.T))\n",
    "        # Rescale actions to [0,1] for rendering\n",
    "        action_dict = dict(zip(['u1','u2','u3','u4'], (np.array(self.actions.T)+1)/2))\n",
    "        return {**state_dict, **action_dict}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Race Track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.  -2.5 -1. ]\n",
      " [ 3.   0.  -1.5]\n",
      " [ 0.5  0.  -1.5]\n",
      " [-2.  -1.5 -2. ]\n",
      " [-2.5  1.  -2. ]\n",
      " [ 0.   1.5 -1.5]\n",
      " [ 2.   2.  -2. ]\n",
      " [ 3.   0.  -1.5]\n",
      " [-1.   0.  -1.5]\n",
      " [-3.5  0.  -1.5]\n",
      " [-1.5 -3.5 -1.5]\n",
      " [ 1.  -1.5 -1. ]\n",
      " [ 3.5 -3.  -1.5]\n",
      " [ 2.  -2.5 -1. ]\n",
      " [ 3.   0.  -1.5]\n",
      " [ 0.5  0.  -1.5]\n",
      " [-2.  -1.5 -2. ]\n",
      " [-2.5  1.  -2. ]\n",
      " [ 0.   1.5 -1.5]\n",
      " [ 2.   2.  -2. ]\n",
      " [ 3.   0.  -1.5]\n",
      " [-1.   0.  -1.5]\n",
      " [-3.5  0.  -1.5]\n",
      " [-1.5 -3.5 -1.5]\n",
      " [ 1.  -1.5 -1. ]\n",
      " [ 3.5 -3.  -1.5]]\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "from quadcopter_animation import animation\n",
    "importlib.reload(animation)\n",
    "\n",
    "# Define the race track\n",
    "# gate_pos = np.array([\n",
    "#     [-1.5,-2,-1.5],\n",
    "#     [1.5,2,-1.5],\n",
    "#     [1.5,-2,-2.5],\n",
    "#     [-1.5,2,-1.5]\n",
    "# ]*2)\n",
    "\n",
    "# gate_pos = np.array([\n",
    "#     [ 2,-1.5,-1.5],\n",
    "#     [ 2, 1.5,-1.5],\n",
    "#     [-2, 1.5,-1.5],\n",
    "#     [-2,-1.5,-1.5]\n",
    "# ]*2)\n",
    "\n",
    "gate_pos = np.array([\n",
    "    [ 2, -2.5, -1],\n",
    "    [ 3, 0, -1.5],\n",
    "    [ 0.5, 0, -1.5],\n",
    "    [-2, -1.5, -2],\n",
    "    [-2.5, 1, -2],\n",
    "    [ 0, 1.5,-1.5],\n",
    "    [ 2, 2, -2],\n",
    "    [ 3, 0, -1.5],\n",
    "    [-1, 0, -1.5],\n",
    "    [-3.5, 0, -1.5],\n",
    "    [-1.5, -3.5,-1.5],\n",
    "    [ 1, -1.5, -1],\n",
    "    [3.5,-3,-1.5]\n",
    "]*2)\n",
    "print(gate_pos)\n",
    "\n",
    "# gate_yaw = np.array([\n",
    "#     0,\n",
    "#     0,\n",
    "#     np.pi,\n",
    "#     np.pi\n",
    "# ]*2)\n",
    "# gate_yaw = np.array([\n",
    "#     np.pi/4,\n",
    "#     3*np.pi/4,\n",
    "#     5*np.pi/4,\n",
    "#     7*np.pi/4\n",
    "# ]*2)\n",
    "\n",
    "gate_yaw = np.array([\n",
    "    np.pi / 2,\n",
    "    np.pi / 2,\n",
    "    3 * np.pi / 2,\n",
    "    3 * np.pi / 4, \n",
    "    np.pi / 4,\n",
    "    0,\n",
    "    0,\n",
    "    3 * np.pi / 2,\n",
    "    np.pi,\n",
    "    3 * np.pi / 2,\n",
    "    0,\n",
    "    np.pi / 2,\n",
    "    3 * np.pi / 2,\n",
    "]*2)\n",
    "\n",
    "# start_pos = gate_pos[0] - np.array([2,0,0])\n",
    "start_pos = gate_pos[0] #- np.array([2,0,0])\n",
    "\n",
    "num = 10\n",
    "env = Quadcopter3DGates(num_envs=num, gates_pos=gate_pos, gate_yaw=gate_yaw, start_pos=start_pos, pause_if_collision=False)\n",
    "\n",
    "# Run a random agent\n",
    "env.reset()\n",
    "\n",
    "done = False\n",
    "def run():\n",
    "    global done\n",
    "    action = np.random.uniform(-1,1, size=(num,4))\n",
    "    state, reward, done, _ = env.step(action)\n",
    "    # print(state[0][-4:])\n",
    "    # print(env.disturbances[0])\n",
    "    if reward[0] > 1:\n",
    "        print(\"reward:\", reward)\n",
    "    return env.render()\n",
    "\n",
    "animation.view(run, gate_pos=gate_pos, gate_yaw=gate_yaw) #, record_steps=1000, show_window=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train PPO Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tavar\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\policies.py:460: UserWarning: As shared layers in the mlp_extractor are removed since SB3 v1.8.0, you should now pass directly a dictionary and not a list (net_arch=dict(pi=..., vf=...) instead of net_arch=[dict(pi=..., vf=...)])\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ActorCriticPolicy(\n",
      "  (features_extractor): FlattenExtractor(\n",
      "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (pi_features_extractor): FlattenExtractor(\n",
      "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (vf_features_extractor): FlattenExtractor(\n",
      "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (mlp_extractor): MlpExtractor(\n",
      "    (policy_net): Sequential(\n",
      "      (0): Linear(in_features=24, out_features=120, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=120, out_features=120, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=120, out_features=120, bias=True)\n",
      "      (5): ReLU()\n",
      "    )\n",
      "    (value_net): Sequential(\n",
      "      (0): Linear(in_features=24, out_features=120, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=120, out_features=120, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=120, out_features=120, bias=True)\n",
      "      (5): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (action_net): Linear(in_features=120, out_features=4, bias=True)\n",
      "  (value_net): Linear(in_features=120, out_features=1, bias=True)\n",
      ")\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from stable_baselines3 import PPO\n",
    "from datetime import datetime\n",
    "from stable_baselines3.common.vec_env import VecMonitor\n",
    "import importlib\n",
    "from quadcopter_animation import animation\n",
    "\n",
    "models_dir = 'models/E2E'\n",
    "log_dir = 'logs/E2E'\n",
    "video_log_dir = 'videos/E2E'\n",
    "\n",
    "if not os.path.exists(models_dir):\n",
    "    os.makedirs(models_dir)\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "if not os.path.exists(video_log_dir):\n",
    "    os.makedirs(video_log_dir)\n",
    "\n",
    "# Date and time string for unique folder names\n",
    "datetime_str = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# Create the environment\n",
    "env = Quadcopter3DGates(num_envs=100, gates_pos=gate_pos, gate_yaw=gate_yaw, start_pos=start_pos, gates_ahead=1)\n",
    "test_env = Quadcopter3DGates(num_envs=10, gates_pos=gate_pos, gate_yaw=gate_yaw, start_pos=start_pos, gates_ahead=1, pause_if_collision=True)\n",
    "\n",
    "# Wrap the environment in a Monitor wrapper\n",
    "env = VecMonitor(env)\n",
    "\n",
    "# disturbance ranges\n",
    "disturbance_ranges = np.array([\n",
    "    [-0.03, 0.03],\n",
    "    [-0.03, 0.03],\n",
    "    [-0.01, 0.01],\n",
    "    [0, 0],\n",
    "    [0, 0],\n",
    "    [-0.5, 0.5],\n",
    "])\n",
    "env.venv.disturbance_ranges = disturbance_ranges\n",
    "test_env.disturbance_ranges = disturbance_ranges\n",
    "\n",
    "# MODEL DEFINITION\n",
    "policy_kwargs = dict(activation_fn=torch.nn.ReLU, net_arch=[dict(pi=[120,120,120], vf=[120,120,120])], log_std_init = 0)\n",
    "model = PPO(\n",
    "    \"MlpPolicy\",\n",
    "    env,\n",
    "    policy_kwargs=policy_kwargs,\n",
    "    verbose=0,\n",
    "    tensorboard_log=log_dir,\n",
    "    n_steps=1000,\n",
    "    batch_size=5000,\n",
    "    n_epochs=10,\n",
    "    gamma=0.999\n",
    ")\n",
    "\n",
    "print(model.policy)\n",
    "print(model.num_timesteps)\n",
    "\n",
    "def animate_policy(model, env, deterministic=False, log_times=False, **kwargs):\n",
    "    env.reset()\n",
    "    def run():\n",
    "        actions, _ = model.predict(env.states, deterministic=deterministic)\n",
    "\n",
    "        states, rewards, dones, infos = env.step(actions)\n",
    "        if log_times:\n",
    "            if rewards[0] == 10:\n",
    "                print(env.step_counts[0]*env.dt)\n",
    "        return env.render()\n",
    "    animation.view(run, gate_pos=env.gate_pos, gate_yaw=env.gate_yaw, **kwargs)\n",
    "\n",
    "# animate untrained policy (use this to set the recording camera position)\n",
    "animate_policy(model, test_env)\n",
    "\n",
    "# training loop saves model every 10 policy rollouts and saves a video animation\n",
    "def train(model, test_env, log_name, n=10000000000):\n",
    "    # save every 10 policy rollouts\n",
    "    TIMESTEPS = model.n_steps*env.num_envs*30\n",
    "    for i in range(0,n):\n",
    "        model.learn(total_timesteps=TIMESTEPS, reset_num_timesteps=False, tb_log_name=log_name)\n",
    "        time_steps = model.num_timesteps\n",
    "        # save model\n",
    "        model.save(models_dir + '/' + log_name + '/' + str(time_steps))\n",
    "        # save policy animation\n",
    "        animate_policy(\n",
    "            model,\n",
    "            test_env,\n",
    "            record_steps=1200,\n",
    "            record_file=video_log_dir + '/' + log_name + '/' + str(time_steps) + '.mp4',\n",
    "            show_window=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\tavar\\Desktop\\Thesis\\Code\\Robin_RL_repo\\quad_RL\\dataset_generator.ipynb Cell 12\u001b[0m line \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/tavar/Desktop/Thesis/Code/Robin_RL_repo/quad_RL/dataset_generator.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# run training loop\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/tavar/Desktop/Thesis/Code/Robin_RL_repo/quad_RL/dataset_generator.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m train(model, test_env, \u001b[39m'\u001b[39;49m\u001b[39mtest1\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\tavar\\Desktop\\Thesis\\Code\\Robin_RL_repo\\quad_RL\\dataset_generator.ipynb Cell 12\u001b[0m line \u001b[0;36mtrain\u001b[1;34m(model, test_env, log_name, n)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tavar/Desktop/Thesis/Code/Robin_RL_repo/quad_RL/dataset_generator.ipynb#X14sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m TIMESTEPS \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mn_steps\u001b[39m*\u001b[39menv\u001b[39m.\u001b[39mnum_envs\u001b[39m*\u001b[39m\u001b[39m30\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tavar/Desktop/Thesis/Code/Robin_RL_repo/quad_RL/dataset_generator.ipynb#X14sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m,n):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/tavar/Desktop/Thesis/Code/Robin_RL_repo/quad_RL/dataset_generator.ipynb#X14sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m     model\u001b[39m.\u001b[39;49mlearn(total_timesteps\u001b[39m=\u001b[39;49mTIMESTEPS, reset_num_timesteps\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, tb_log_name\u001b[39m=\u001b[39;49mlog_name)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tavar/Desktop/Thesis/Code/Robin_RL_repo/quad_RL/dataset_generator.ipynb#X14sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m     time_steps \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mnum_timesteps\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tavar/Desktop/Thesis/Code/Robin_RL_repo/quad_RL/dataset_generator.ipynb#X14sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m     \u001b[39m# save model\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tavar\\anaconda3\\lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:308\u001b[0m, in \u001b[0;36mPPO.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    299\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlearn\u001b[39m(\n\u001b[0;32m    300\u001b[0m     \u001b[39mself\u001b[39m: SelfPPO,\n\u001b[0;32m    301\u001b[0m     total_timesteps: \u001b[39mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    306\u001b[0m     progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    307\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m SelfPPO:\n\u001b[1;32m--> 308\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mlearn(\n\u001b[0;32m    309\u001b[0m         total_timesteps\u001b[39m=\u001b[39;49mtotal_timesteps,\n\u001b[0;32m    310\u001b[0m         callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[0;32m    311\u001b[0m         log_interval\u001b[39m=\u001b[39;49mlog_interval,\n\u001b[0;32m    312\u001b[0m         tb_log_name\u001b[39m=\u001b[39;49mtb_log_name,\n\u001b[0;32m    313\u001b[0m         reset_num_timesteps\u001b[39m=\u001b[39;49mreset_num_timesteps,\n\u001b[0;32m    314\u001b[0m         progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[0;32m    315\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\tavar\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:259\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_timesteps \u001b[39m<\u001b[39m total_timesteps:\n\u001b[1;32m--> 259\u001b[0m     continue_training \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollect_rollouts(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv, callback, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrollout_buffer, n_rollout_steps\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_steps)\n\u001b[0;32m    261\u001b[0m     \u001b[39mif\u001b[39;00m continue_training \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[0;32m    262\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tavar\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:169\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.collect_rollouts\u001b[1;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[39mwith\u001b[39;00m th\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m    167\u001b[0m     \u001b[39m# Convert to pytorch tensor or to TensorDict\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     obs_tensor \u001b[39m=\u001b[39m obs_as_tensor(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_last_obs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m--> 169\u001b[0m     actions, values, log_probs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpolicy(obs_tensor)\n\u001b[0;32m    170\u001b[0m actions \u001b[39m=\u001b[39m actions\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\n\u001b[0;32m    172\u001b[0m \u001b[39m# Rescale and perform action\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tavar\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\tavar\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tavar\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\policies.py:628\u001b[0m, in \u001b[0;36mActorCriticPolicy.forward\u001b[1;34m(self, obs, deterministic)\u001b[0m\n\u001b[0;32m    626\u001b[0m distribution \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_action_dist_from_latent(latent_pi)\n\u001b[0;32m    627\u001b[0m actions \u001b[39m=\u001b[39m distribution\u001b[39m.\u001b[39mget_actions(deterministic\u001b[39m=\u001b[39mdeterministic)\n\u001b[1;32m--> 628\u001b[0m log_prob \u001b[39m=\u001b[39m distribution\u001b[39m.\u001b[39;49mlog_prob(actions)\n\u001b[0;32m    629\u001b[0m actions \u001b[39m=\u001b[39m actions\u001b[39m.\u001b[39mreshape((\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_space\u001b[39m.\u001b[39mshape))\n\u001b[0;32m    630\u001b[0m \u001b[39mreturn\u001b[39;00m actions, values, log_prob\n",
      "File \u001b[1;32mc:\\Users\\tavar\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\distributions.py:175\u001b[0m, in \u001b[0;36mDiagGaussianDistribution.log_prob\u001b[1;34m(self, actions)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlog_prob\u001b[39m(\u001b[39mself\u001b[39m, actions: th\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m th\u001b[39m.\u001b[39mTensor:\n\u001b[0;32m    168\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    169\u001b[0m \u001b[39m    Get the log probabilities of actions according to the distribution.\u001b[39;00m\n\u001b[0;32m    170\u001b[0m \u001b[39m    Note that you must first call the ``proba_distribution()`` method.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[39m    :return:\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 175\u001b[0m     log_prob \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdistribution\u001b[39m.\u001b[39;49mlog_prob(actions)\n\u001b[0;32m    176\u001b[0m     \u001b[39mreturn\u001b[39;00m sum_independent_dims(log_prob)\n",
      "File \u001b[1;32mc:\\Users\\tavar\\anaconda3\\lib\\site-packages\\torch\\distributions\\normal.py:86\u001b[0m, in \u001b[0;36mNormal.log_prob\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m     81\u001b[0m var \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscale\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m\n\u001b[0;32m     82\u001b[0m log_scale \u001b[39m=\u001b[39m (\n\u001b[0;32m     83\u001b[0m     math\u001b[39m.\u001b[39mlog(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscale) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscale, Real) \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscale\u001b[39m.\u001b[39mlog()\n\u001b[0;32m     84\u001b[0m )\n\u001b[0;32m     85\u001b[0m \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m---> 86\u001b[0m     \u001b[39m-\u001b[39;49m((value \u001b[39m-\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloc) \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m \u001b[39m2\u001b[39;49m) \u001b[39m/\u001b[39;49m (\u001b[39m2\u001b[39;49m \u001b[39m*\u001b[39;49m var)\n\u001b[0;32m     87\u001b[0m     \u001b[39m-\u001b[39;49m log_scale\n\u001b[0;32m     88\u001b[0m     \u001b[39m-\u001b[39;49m math\u001b[39m.\u001b[39;49mlog(math\u001b[39m.\u001b[39;49msqrt(\u001b[39m2\u001b[39;49m \u001b[39m*\u001b[39;49m math\u001b[39m.\u001b[39;49mpi))\n\u001b[0;32m     89\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# run training loop\n",
    "train(model, test_env, 'test1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate PPO model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animate_policy(model, test_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate dataset with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def generate_gate():\n",
    "    gate_pos = [random.uniform(-3, 3), random.uniform(-3, 3), random.uniform(-2, -1)]\n",
    "    gate_yaw = random.uniform(0, 2 * np.pi)\n",
    "    return gate_pos, gate_yaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NETWORK:\n",
      "Sequential(\n",
      "  (0): Linear(in_features=24, out_features=120, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=120, out_features=120, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=120, out_features=120, bias=True)\n",
      "  (5): ReLU()\n",
      "  (6): Linear(in_features=120, out_features=4, bias=True)\n",
      ")\n",
      "<stable_baselines3.common.distributions.DiagGaussianDistribution object at 0x000001D64A788EE0>\n",
      "Parameter containing:\n",
      "tensor([-1.8489, -1.8768, -1.9291, -1.8823], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([0.1574, 0.1531, 0.1453, 0.1522], device='cuda:0',\n",
      "       grad_fn=<ExpBackward0>)\n",
      "[0.15741545 0.15308292 0.14528348 0.15223223]\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# E2E_Net\n",
    "path = 'models/E2E/test1/84100000.zip'\n",
    "\n",
    "model = PPO.load(path)\n",
    "\n",
    "# get network\n",
    "network = list(model.policy.mlp_extractor.policy_net) + [model.policy.action_net]\n",
    "network = nn.Sequential(*network)\n",
    "print('NETWORK:')\n",
    "print(network)\n",
    "\n",
    "print(model.policy.action_dist)\n",
    "print(model.policy.log_std)\n",
    "print(model.policy.log_std.exp())\n",
    "network_std = model.policy.log_std.exp().cpu().detach().numpy()\n",
    "print(network_std)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Quadcopter3DGatesSim(VecEnv):\n",
    "    def __init__(self,\n",
    "                 num_envs,\n",
    "                 start_pos,\n",
    "                 gates_ahead=0,\n",
    "                 pause_if_collision=False,\n",
    "                 ):\n",
    "        \n",
    "        # Define the race track\n",
    "        gates_pos = []\n",
    "        gates_yaw = []\n",
    "        for _ in range(gates_ahead + 1):\n",
    "            gate_pos, gate_yaw = generate_gate()\n",
    "            gates_pos.append(gate_pos)\n",
    "            gates_yaw.append(gate_yaw)\n",
    "        self.gate_pos = np.array(gates_pos * 2).astype(np.float32)\n",
    "        self.gate_yaw = np.array(gates_yaw * 2).astype(np.float32)\n",
    "        self.start_pos = np.array(start_pos).astype(np.float32)\n",
    "        self.num_gates = gates_ahead + 1\n",
    "        self.gates_ahead = gates_ahead\n",
    "        \n",
    "        # Pause if collision\n",
    "        self.pause_if_collision = pause_if_collision\n",
    "\n",
    "        # Calculate relative gates\n",
    "        # pos,yaw of gate i in reference frame of gate i-1 (assumes a looped track)\n",
    "        self.gate_pos_rel = np.zeros((self.num_gates,3), dtype=np.float32)\n",
    "        self.gate_yaw_rel = np.zeros(self.num_gates, dtype=np.float32)\n",
    "        for i in range(0,self.num_gates):\n",
    "            self.gate_pos_rel[i] = self.gate_pos[i] - self.gate_pos[i-1]\n",
    "            # Rotation matrix\n",
    "            R = np.array([\n",
    "                [np.cos(self.gate_yaw[i-1]), np.sin(self.gate_yaw[i-1])],\n",
    "                [-np.sin(self.gate_yaw[i-1]), np.cos(self.gate_yaw[i-1])]\n",
    "            ])\n",
    "            self.gate_pos_rel[i,0:2] = R@self.gate_pos_rel[i,0:2]\n",
    "            self.gate_yaw_rel[i] = self.gate_yaw[i] - self.gate_yaw[i-1]\n",
    "\n",
    "        # Define the target gate for each environment\n",
    "        self.target_gates = np.zeros(num_envs, dtype=int)\n",
    "\n",
    "        # action space: [cmd1, cmd2, cmd3, cmd4]\n",
    "        action_space = Box(low=-1, high=1, shape=(4,))\n",
    "\n",
    "        # observation space: pos[G], vel[G], att[eulerB->G], rates[B], rpms, future_gates[G], future_gate_dirs[G]\n",
    "        # [G] = reference frame aligned with target gate\n",
    "        # [B] = body frame\n",
    "        self.state_len = 16+4*self.gates_ahead + 4\n",
    "        observation_space = Box(\n",
    "            low  = np.array([-np.inf]*self.state_len),\n",
    "            high = np.array([ np.inf]*self.state_len)\n",
    "        )\n",
    "\n",
    "        # Initialize the VecEnv\n",
    "        VecEnv.__init__(self,num_envs, observation_space, action_space)\n",
    "\n",
    "        # world state: pos[W], vel[W], att[eulerB->W], rates[B], rpms\n",
    "        self.world_states = np.zeros((num_envs,16), dtype=np.float32)\n",
    "        # observation state\n",
    "        self.states = np.zeros((num_envs,self.state_len), dtype=np.float32)\n",
    "\n",
    "        # Define any other environment-specific parameters\n",
    "        self.max_steps = 3000      # Maximum number of steps in an episode\n",
    "        self.dt = np.float32(0.01) # Time step duration\n",
    "\n",
    "        self.step_counts = np.zeros(num_envs, dtype=int)\n",
    "        self.actions = np.zeros((num_envs,4), dtype=np.float32)\n",
    "        self.dones = np.zeros(num_envs, dtype=bool)\n",
    "        self.final_gate_passed = np.zeros(num_envs, dtype=bool)\n",
    "\n",
    "        self.update_states = self.update_states_gate\n",
    "        \n",
    "        self.disturbance_ranges = np.zeros((6,2), dtype=np.float32)\n",
    "        self.disturbances = np.zeros((num_envs,6), dtype=np.float32)\n",
    "\n",
    "        self.disturbance_scale = 1\n",
    "\n",
    "        self.pause = False\n",
    "\n",
    "    def update_states_world(self):\n",
    "        self.states = self.world_states\n",
    "\n",
    "    def update_states_gate(self):\n",
    "        # Transform pos and vel in gate frame\n",
    "        gate_pos = self.gate_pos[self.target_gates%self.num_gates]\n",
    "        gate_yaw = self.gate_yaw[self.target_gates%self.num_gates]\n",
    "\n",
    "        # Rotation matrix from world frame to gate frame\n",
    "        R = np.array([\n",
    "            [np.cos(gate_yaw), np.sin(gate_yaw)],\n",
    "            [-np.sin(gate_yaw), np.cos(gate_yaw)]\n",
    "        ]).transpose((2,1,0))\n",
    "\n",
    "        # new state array to prevent the weird bug related to indexing ([:] syntax)\n",
    "        new_states = np.zeros_like(self.states)\n",
    "\n",
    "        # Update positions\n",
    "        pos_W = self.world_states[:,0:3]\n",
    "        pos_G = (pos_W[:,np.newaxis,0:2] - gate_pos[:,np.newaxis,0:2]) @ R\n",
    "        new_states[:,0:2] = pos_G[:,0,:]\n",
    "        new_states[:,2] = pos_W[:,2] - gate_pos[:,2]\n",
    "\n",
    "        # Update velocities\n",
    "        vel_W = self.world_states[:,3:6]\n",
    "        vel_G = (vel_W[:,np.newaxis,0:2]) @ R\n",
    "        new_states[:,3:5] = vel_G[:,0,:]\n",
    "        new_states[:,5] = vel_W[:,2]\n",
    "\n",
    "        # Update attitude\n",
    "        new_states[:,6:8] = self.world_states[:,6:8]\n",
    "        yaw = self.world_states[:,8] - gate_yaw\n",
    "        yaw %= 2*np.pi\n",
    "        yaw[yaw > np.pi] -= 2*np.pi\n",
    "        yaw[yaw < -np.pi] += 2*np.pi\n",
    "        new_states[:,8] = yaw\n",
    "\n",
    "        # Update rates\n",
    "        new_states[:,9:12] = self.world_states[:,9:12]\n",
    "\n",
    "        # Update rpms\n",
    "        new_states[:,12:16] = self.world_states[:,12:16]\n",
    "\n",
    "        # Update future gates relative to current gate ([0,0,0,0] for out of bounds)\n",
    "        for i in range(self.gates_ahead):\n",
    "            indices = (self.target_gates+i+1)\n",
    "            # loop when out of bounds\n",
    "            indices = indices % self.num_gates\n",
    "            valid = indices < self.num_gates\n",
    "            new_states[valid,16+4*i:16+4*i+3] = self.gate_pos_rel[indices[valid]]\n",
    "            new_states[valid,16+4*i+3] = self.gate_yaw_rel[indices[valid]]\n",
    "        \n",
    "        Mx = self.disturbances[:,0]\n",
    "        My = self.disturbances[:,1]\n",
    "        Mz = self.disturbances[:,2]\n",
    "        Fz = self.disturbances[:,5]\n",
    "\n",
    "        Mx_min = self.disturbance_ranges[0,0]\n",
    "        Mx_max = self.disturbance_ranges[0,1]\n",
    "        if Mx_min == Mx_max:\n",
    "            Mx_min -= 1\n",
    "            Mx_max += 1\n",
    "\n",
    "        My_min = self.disturbance_ranges[1,0]\n",
    "        My_max = self.disturbance_ranges[1,1]\n",
    "        if My_min == My_max:\n",
    "            My_min -= 1\n",
    "            My_max += 1\n",
    "        \n",
    "        Mz_min = self.disturbance_ranges[2,0]\n",
    "        Mz_max = self.disturbance_ranges[2,1]\n",
    "        if Mz_min == Mz_max:\n",
    "            Mz_min -= 1\n",
    "            Mz_max += 1\n",
    "\n",
    "        Fz_min = self.disturbance_ranges[5,0]\n",
    "        Fz_max = self.disturbance_ranges[5,1]\n",
    "        if Fz_min == Fz_max:\n",
    "            Fz_min -= 1\n",
    "            Fz_max += 1\n",
    "\n",
    "        new_states[:,16+4*self.gates_ahead:] = np.array([\n",
    "            2*(Mx-Mx_min)/(Mx_max-Mx_min)-1, # Mx\n",
    "            2*(My-My_min)/(My_max-My_min)-1, # My\n",
    "            2*(Mz-Mz_min)/(Mz_max-Mz_min)-1, # Mz\n",
    "            2*(Fz-Fz_min)/(Fz_max-Fz_min)-1, # Fz\n",
    "        ]).T\n",
    "\n",
    "        self.states = new_states\n",
    "\n",
    "    def reset_(self, dones):\n",
    "        num_reset = dones.sum()\n",
    "\n",
    "        x0 = np.random.uniform(-0.5,0.5, size=(num_reset,)) + self.start_pos[0]\n",
    "        y0 = np.random.uniform(-0.5,0.5, size=(num_reset,)) + self.start_pos[1]\n",
    "        z0 = np.random.uniform(-0.5,0.5, size=(num_reset,)) + self.start_pos[2]\n",
    "        \n",
    "        vx0 = np.random.uniform(-0.5,0.5, size=(num_reset,))\n",
    "        vy0 = np.random.uniform(-0.5,0.5, size=(num_reset,))\n",
    "        vz0 = np.random.uniform(-0.5,0.5, size=(num_reset,))\n",
    "        \n",
    "        phi0   = np.random.uniform(-np.pi/9,np.pi/9, size=(num_reset,))\n",
    "        theta0 = np.random.uniform(-np.pi/9,np.pi/9, size=(num_reset,))\n",
    "        psi0   = np.random.uniform(-np.pi,np.pi, size=(num_reset,))\n",
    "        \n",
    "        p0 = np.random.uniform(-0.1,0.1, size=(num_reset,))\n",
    "        q0 = np.random.uniform(-0.1,0.1, size=(num_reset,))\n",
    "        r0 = np.random.uniform(-0.1,0.1, size=(num_reset,))\n",
    "        \n",
    "        w10 = np.random.uniform(-1,1, size=(num_reset,))\n",
    "        w20 = np.random.uniform(-1,1, size=(num_reset,))\n",
    "        w30 = np.random.uniform(-1,1, size=(num_reset,))\n",
    "        w40 = np.random.uniform(-1,1, size=(num_reset,))\n",
    "\n",
    "        self.world_states[dones] = np.stack([x0, y0, z0, vx0, vy0, vz0, phi0, theta0, psi0, p0, q0, r0, w10, w20, w30, w40], axis=1)\n",
    "\n",
    "        self.step_counts[dones] = np.zeros(num_reset)\n",
    "        \n",
    "        self.target_gates[dones] = np.zeros(num_reset, dtype=int)\n",
    "\n",
    "        M_ext_x = np.random.uniform(self.disturbance_ranges[0,0], self.disturbance_ranges[0,1], size=(num_reset,))\n",
    "        M_ext_y = np.random.uniform(self.disturbance_ranges[1,0], self.disturbance_ranges[1,1], size=(num_reset,))\n",
    "        M_ext_z = np.random.uniform(self.disturbance_ranges[2,0], self.disturbance_ranges[2,1], size=(num_reset,))\n",
    "        F_ext_x = np.random.uniform(self.disturbance_ranges[3,0], self.disturbance_ranges[3,1], size=(num_reset,))\n",
    "        F_ext_y = np.random.uniform(self.disturbance_ranges[4,0], self.disturbance_ranges[4,1], size=(num_reset,))\n",
    "        F_ext_z = np.random.uniform(self.disturbance_ranges[5,0], self.disturbance_ranges[5,1], size=(num_reset,))\n",
    "        \n",
    "        self.disturbances[dones] = self.disturbance_scale*np.stack([M_ext_x, M_ext_y, M_ext_z, F_ext_x, F_ext_y, F_ext_z], axis=1)\n",
    "\n",
    "        # update states\n",
    "        self.update_states()\n",
    "        return self.states\n",
    "    \n",
    "    def reset(self):\n",
    "        return self.reset_(np.ones(self.num_envs, dtype=bool))\n",
    "\n",
    "    def step_async(self, actions):\n",
    "        self.actions = actions\n",
    "    \n",
    "    def step_wait(self):\n",
    "        # Residual nn model\n",
    "        d = np.zeros((self.num_envs,6), dtype=np.float32)\n",
    "        thurst, moment = thrust_moment_model_world_states(self.world_states)\n",
    "        d[:,0:3] = moment\n",
    "        d[:,5:6] = thurst\n",
    "\n",
    "        # Add disturbances\n",
    "        d += self.disturbances\n",
    "        \n",
    "\n",
    "        new_states = self.world_states + self.dt*f_func(self.world_states.T, self.actions.T, d.T).T\n",
    "        # new_states = self.world_states + self.dt*f_func(self.world_states.T, self.actions.T, self.disturbances[self.step_counts].T).T\n",
    "        self.step_counts += 1\n",
    "\n",
    "        pos_old = self.world_states[:,0:3]\n",
    "        pos_new = new_states[:,0:3]\n",
    "        pos_gate = self.gate_pos[self.target_gates%self.num_gates]\n",
    "        yaw_gate = self.gate_yaw[self.target_gates%self.num_gates]\n",
    "\n",
    "        # Rewards\n",
    "        d2g_old = np.linalg.norm(pos_old - pos_gate, axis=1)\n",
    "        d2g_new = np.linalg.norm(pos_new - pos_gate, axis=1)\n",
    "        rat_penalty = 0*0.01*np.linalg.norm(new_states[:,9:12], axis=1)\n",
    "        rewards = d2g_old - d2g_new - rat_penalty\n",
    "        \n",
    "        # Gate passing/collision\n",
    "        normal = np.array([np.cos(yaw_gate), np.sin(yaw_gate)]).T\n",
    "        # dot product of normal and position vector over axis 1\n",
    "        pos_old_projected = (pos_old[:,0]-pos_gate[:,0])*normal[:,0] + (pos_old[:,1]-pos_gate[:,1])*normal[:,1]\n",
    "        pos_new_projected = (pos_new[:,0]-pos_gate[:,0])*normal[:,0] + (pos_new[:,1]-pos_gate[:,1])*normal[:,1]\n",
    "        passed_gate_plane = (pos_old_projected < 0) & (pos_new_projected > 0)\n",
    "        gate_passed = passed_gate_plane & np.all(np.abs(pos_new - pos_gate)<0.5, axis=1)\n",
    "        gate_collision = passed_gate_plane & np.any(np.abs(pos_new - pos_gate)>0.5, axis=1)\n",
    "\n",
    "        if passed_gate_plane:\n",
    "            new_gate_pos, new_gate_yaw = generate_gate()\n",
    "            gates_pos = [self.gate_pos[1].tolist(), new_gate_pos]\n",
    "            gates_yaw = [self.gate_yaw[1].tolist(), new_gate_yaw]\n",
    "            self.gate_pos = np.array(gates_pos * 2).astype(np.float32)\n",
    "            self.gate_yaw = np.array(gates_yaw * 2).astype(np.float32)\n",
    "            self.gate_pos_rel = np.zeros((self.num_gates,3), dtype=np.float32)\n",
    "            self.gate_yaw_rel = np.zeros(self.num_gates, dtype=np.float32)\n",
    "            for i in range(0,self.num_gates):\n",
    "                self.gate_pos_rel[i] = self.gate_pos[i] - self.gate_pos[i-1]\n",
    "                # Rotation matrix\n",
    "                R = np.array([\n",
    "                    [np.cos(self.gate_yaw[i-1]), np.sin(self.gate_yaw[i-1])],\n",
    "                    [-np.sin(self.gate_yaw[i-1]), np.cos(self.gate_yaw[i-1])]\n",
    "                ])\n",
    "                self.gate_pos_rel[i,0:2] = R@self.gate_pos_rel[i,0:2]\n",
    "                self.gate_yaw_rel[i] = self.gate_yaw[i] - self.gate_yaw[i-1]\n",
    "        \n",
    "        # Gate reward + dist penalty\n",
    "        rewards[gate_passed] = 10 - 10*d2g_new[gate_passed]\n",
    "        \n",
    "        # Gate collision penalty\n",
    "        rewards[gate_collision] = -10\n",
    "\n",
    "        # Ground collision penalty (z > 0)\n",
    "        ground_collision = new_states[:,2] > 0\n",
    "        rewards[ground_collision] = -10\n",
    "        \n",
    "        # Check out of bounds\n",
    "        # outside grid abs(x,y)>10\n",
    "        # prevent numerical issues: abs(p,q,r) < 1000\n",
    "        out_of_bounds = np.any(np.abs(new_states[:,0:2]) > 10, axis=1) | np.any(np.abs(new_states[:,9:12]) > 1000, axis=1)\n",
    "        rewards[out_of_bounds] = -10\n",
    "        \n",
    "        # Check number of steps\n",
    "        max_steps_reached = self.step_counts >= self.max_steps\n",
    "\n",
    "        # Update target gate\n",
    "        self.target_gates[gate_passed] += 1\n",
    "        self.target_gates[gate_passed] %= self.num_gates\n",
    "        \n",
    "        # Check if final gate has been passed\n",
    "        # self.final_gate_passed = self.target_gates >= self.num_gates\n",
    "\n",
    "        # give reward for passing final gate\n",
    "        rewards[self.final_gate_passed] = 10\n",
    "        \n",
    "        # Check if the episode is done\n",
    "        dones = max_steps_reached | ground_collision | gate_collision | out_of_bounds #| self.final_gate_passed\n",
    "        self.dones = dones\n",
    "        \n",
    "        # Pause if collision\n",
    "        if self.pause:\n",
    "            dones = dones & ~dones\n",
    "            self.dones = dones\n",
    "        elif self.pause_if_collision:\n",
    "            # dones = max_steps_reached | final_gate_passed | out_of_bounds\n",
    "            update = ~dones #~(gate_collision | ground_collision)\n",
    "            # Update world states\n",
    "            self.world_states[update] = new_states[update]\n",
    "            self.update_states()\n",
    "            # Reset env if done (and update states)\n",
    "            # self.reset_(dones)\n",
    "        else:\n",
    "            # Update world states\n",
    "            self.world_states = new_states\n",
    "            # reset env if done (and update states)\n",
    "            self.reset_(dones)\n",
    "\n",
    "\n",
    "        # Write info dicts\n",
    "        infos = [{}] * self.num_envs\n",
    "        for i in range(self.num_envs):\n",
    "            if dones[i]:\n",
    "                infos[i][\"terminal_observation\"] = self.states[i]\n",
    "            if max_steps_reached[i]:\n",
    "                infos[i][\"TimeLimit.truncated\"] = True\n",
    "        return self.states, rewards, dones, infos\n",
    "    \n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "    def seed(self, seed=None):\n",
    "        pass\n",
    "\n",
    "    def get_attr(self, attr_name, indices=None):\n",
    "        pass\n",
    "\n",
    "    def set_attr(self, attr_name, value, indices=None):\n",
    "        pass\n",
    "\n",
    "    def env_method(self, method_name, *method_args, indices=None, **method_kwargs):\n",
    "        pass\n",
    "\n",
    "    def env_is_wrapped(self, wrapper_class, indices=None):\n",
    "        return [False]*self.num_envs\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        # Outputs a dict containing all information for rendering\n",
    "        state_dict = dict(zip(['x','y','z','vx','vy','vz','phi','theta','psi','p','q','r','w1','w2','w3','w4'], self.world_states.T))\n",
    "        # Rescale actions to [0,1] for rendering\n",
    "        action_dict = dict(zip(['u1','u2','u3','u4'], (np.array(self.actions.T)+1)/2))\n",
    "        disturbances_dict = dict(zip(['Mx','My','Mz','Fz'], (np.array([self.disturbances[0,0]]).astype(np.float32),\n",
    "                                                             np.array([self.disturbances[0,1]]).astype(np.float32),\n",
    "                                                             np.array([self.disturbances[0,2]]).astype(np.float32),\n",
    "                                                             np.array([self.disturbances[0,5]]).astype(np.float32))))\n",
    "        # print([self.gate_pos[1]].append(self.gate_yaw[1]))\n",
    "        next_gate_values = self.gate_pos[1].tolist()\n",
    "        next_gate_values.append(self.gate_yaw[1])\n",
    "        next_gate_dict = dict(zip(['gate_x','gate_y','gate_z','gate_yaw'], (np.array([self.gate_pos[1, 0]]).astype(np.float32),\n",
    "                                                                            np.array([self.gate_pos[1, 1]]).astype(np.float32),\n",
    "                                                                            np.array([self.gate_pos[1, 2]]).astype(np.float32),\n",
    "                                                                            np.array([self.gate_yaw[1]]).astype(np.float32))))\n",
    "        return {**state_dict, **disturbances_dict, **next_gate_dict, **action_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import time\n",
    "\n",
    "def make_dataset(model, env, round, deterministic=False, log_times=False, **kwargs):\n",
    "    env.reset()\n",
    "    initial_time = time.time()\n",
    "    def run():\n",
    "        actions, _ = model.predict(env.states, deterministic=deterministic)\n",
    "        states, rewards, dones, infos = env.step(actions)\n",
    "        if log_times:\n",
    "            if rewards[0] == 10:\n",
    "                print(env.step_counts[0]*env.dt)\n",
    "        return env.render()\n",
    "    \n",
    "    csv_file_path = 'data.csv'\n",
    "    file_exists = True\n",
    "    try:\n",
    "        with open(csv_file_path, 'r') as file:\n",
    "            pass\n",
    "    except FileNotFoundError:\n",
    "        file_exists = False\n",
    "    \n",
    "    existing_data = []\n",
    "\n",
    "    while (len(existing_data) < 200):\n",
    "        data = run()\n",
    "        new_data = {key: value[0] for key, value in data.items()}\n",
    "\n",
    "        # Add your dictionary to the existing data\n",
    "        existing_data.append(new_data)\n",
    "\n",
    "        # Write the updated data to the CSV file\n",
    "        with open(csv_file_path, 'a', newline='') as file:\n",
    "            fieldnames = data.keys()\n",
    "            writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "            # Write header only if the file is newly created\n",
    "            if not file_exists:\n",
    "                writer.writeheader()\n",
    "                file_exists = True\n",
    "\n",
    "            # Write new values\n",
    "            writer.writerow(new_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: 0\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    print(\"Start:\", i)\n",
    "    start_pos = [random.uniform(-3, 3), random.uniform(-3, 3), random.uniform(-2, -1)]\n",
    "    test_env = Quadcopter3DGatesSim(num_envs=1, start_pos=start_pos, gates_ahead=1, pause_if_collision=True)\n",
    "    ranges = np.array([\n",
    "        [-0.03, 0.03],\n",
    "        [-0.03, 0.03],\n",
    "        [-0.01, 0.01],\n",
    "        [0, 0],\n",
    "        [0, 0],\n",
    "        [-0.5, 0.5],\n",
    "    ])\n",
    "    test_env.disturbance_ranges = ranges\n",
    "\n",
    "    make_dataset(model, test_env, i, deterministic=False, log_times=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
